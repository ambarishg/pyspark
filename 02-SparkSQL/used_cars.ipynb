{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7a3242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/26 15:10:28 WARN Utils: Your hostname, DESKTOP-OR4MSG8 resolves to a loopback address: 127.0.1.1; using 172.18.224.90 instead (on interface eth0)\n",
      "21/11/26 15:10:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ambarish/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/26 15:10:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "path = \"/mnt/c/Ambarish/UsedCars/input/vehicles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f01252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for our data\n",
    "schema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), False),\n",
    "   StructField(\"url\", StringType(), False),\n",
    "   StructField(\"region\", StringType(), False),\n",
    "   StructField(\"region_url\", StringType(), False),\n",
    "   StructField(\"price\", LongType(), False),\n",
    "   StructField(\"year\", IntegerType(), False),\n",
    "   StructField(\"manufacturer\", StringType(), False),\n",
    "   StructField(\"model\", StringType(), False),\n",
    "   StructField(\"condition\", StringType(), False),\n",
    "   StructField(\"cylinders\", StringType(), False),\n",
    "   StructField(\"fuel\", StringType(), False),\n",
    "   StructField(\"odometer\", StringType(), False),\n",
    "   StructField(\"title_status\", StringType(), False),\n",
    "   StructField(\"transmission\", StringType(), False),\n",
    "   StructField(\"VIN\", StringType(), False),\n",
    "   StructField(\"drive\", StringType(), False),\n",
    "   StructField(\"size\", StringType(), False),\n",
    "   StructField(\"type\", StringType(), False),\n",
    "   StructField(\"paint_color\", StringType(), False),\n",
    "   StructField(\"image_url\", StringType(), False),\n",
    "   StructField(\"description\", StringType(), False),\n",
    "   StructField(\"county\", StringType(), False),\n",
    "   StructField(\"state\", StringType(), False),\n",
    "   StructField(\"lat\", StringType(), False),\n",
    "   StructField(\"long\", StringType(), False),\n",
    "   StructField(\"posting_date\", StringType(), False)]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be44306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(path,\n",
    "                     format=\"csv\", \n",
    "                     sep=\",\", \n",
    "                     schema =schema, \n",
    "                     header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7a328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- region_url: string (nullable = true)\n",
      " |-- price: long (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- cylinders: string (nullable = true)\n",
      " |-- fuel: string (nullable = true)\n",
      " |-- odometer: string (nullable = true)\n",
      " |-- title_status: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- drive: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- paint_color: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- posting_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c2e742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a52a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/26 15:10:34 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
      "|  Id|                 url|      region|          region_url|price|year|manufacturer|model|condition|cylinders|fuel|odometer|title_status|transmission| VIN|drive|size|type|paint_color|image_url|description|county|state| lat|long|posting_date|\n",
      "+----+--------------------+------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
      "|null|https://prescott....|    prescott|https://prescott....| 6000|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   az|null|null|        null|\n",
      "|null|https://fayar.cra...|fayetteville|https://fayar.cra...|11900|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   ar|null|null|        null|\n",
      "|null|https://keys.crai...|florida keys|https://keys.crai...|21000|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   fl|null|null|        null|\n",
      "+----+--------------------+------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942d7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|cylinders|\n",
      "+---------+\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"cylinders\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f9a6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|cylinders|\n",
      "+---------+\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions\n",
    "\n",
    "split_col = functions.split(df['cylinders'], ' ')\n",
    "df3 = df.withColumn('cylinders', split_col.getItem(0))\n",
    "df3.select(\"cylinders\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42ed15",
   "metadata": {},
   "source": [
    "# Casting into proper data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41daab43",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da72e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.price > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a0f02",
   "metadata": {},
   "source": [
    "# Summary of Price of Used Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "270258b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|               price|\n",
      "+-------+--------------------+\n",
      "|  count|              393985|\n",
      "|   mean|   81477.62804929122|\n",
      "| stddev|1.2680636885188837E7|\n",
      "|    min|                   1|\n",
      "|    max|          3736928711|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe(['price']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe5199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"used_cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0aa128",
   "metadata": {},
   "source": [
    "# Count of Cars where there is an Invalid year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0e8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:==========================================>               (8 + 3) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|0       |\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT count(1) \\\n",
    "FROM used_cars \\\n",
    "WHERE year < 0\"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19d3a0",
   "metadata": {},
   "source": [
    "# Count of Cars of VINS appearing more than Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77af4547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|VIN              |CountVIN|\n",
      "+-----------------+--------+\n",
      "|WBALM1C55BE393513|97      |\n",
      "|ZARFAEDN0J7565017|24      |\n",
      "|KNDJ23AU8L7109397|2       |\n",
      "|2T2ZK1BA8DC129687|3       |\n",
      "|ZFBERFAT9F6A76965|3       |\n",
      "|ZARFAEEN3H7558717|2       |\n",
      "|1FDAX57P26ED52391|2       |\n",
      "|3GNCJNSB5LL189135|3       |\n",
      "|1GT120E88FF513709|9       |\n",
      "|1GYS3CEF5DR103313|2       |\n",
      "|1FADP5AU7DL503286|2       |\n",
      "|WBA8K3C56JA023782|3       |\n",
      "|WAUR4AF53JA008266|41      |\n",
      "|1FT7W2BT7KED12158|4       |\n",
      "|1FTYR1ZM0JKA98201|3       |\n",
      "|1G6AR5SS8J0137892|27      |\n",
      "|ZFBHRFAB0M6T14104|3       |\n",
      "|1N4AZ0CPXDC415680|2       |\n",
      "|JTEBU5JR2F5271740|2       |\n",
      "|1FTBF2A67BED05863|3       |\n",
      "|4T1BK1EB1DU028175|4       |\n",
      "|JTDKN3DU8C5391950|2       |\n",
      "|232709           |2       |\n",
      "|KNMAT2MT7GP679827|8       |\n",
      "|1J4FA49S11P364952|4       |\n",
      "+-----------------+--------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT VIN , COUNT(1) as CountVIN \\\n",
    "FROM used_cars \\\n",
    "GROUP BY VIN HAVING CountVIN > 1\"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f411c4",
   "metadata": {},
   "source": [
    "# Count of Cars having same URL more than Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897e45cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|url|CountURL|\n",
      "+---+--------+\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT url , COUNT(1) as CountURL \\\n",
    "FROM used_cars \\\n",
    "GROUP BY url  HAVING CountURL > 1\"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76264fd7",
   "metadata": {},
   "source": [
    "# Cars by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96e9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------+\n",
      "|region                 |COUNTREGION|\n",
      "+-----------------------+-----------+\n",
      "|columbus               |3392       |\n",
      "|jacksonville           |3177       |\n",
      "|omaha / council bluffs |2967       |\n",
      "|new hampshire          |2944       |\n",
      "|grand rapids           |2934       |\n",
      "|milwaukee              |2917       |\n",
      "|central NJ             |2905       |\n",
      "|tampa bay area         |2894       |\n",
      "|sarasota-bradenton     |2882       |\n",
      "|kansas city, MO        |2876       |\n",
      "|nashville              |2867       |\n",
      "|las vegas              |2865       |\n",
      "|boston                 |2856       |\n",
      "|detroit metro          |2854       |\n",
      "|orlando                |2851       |\n",
      "|chicago                |2851       |\n",
      "|south florida          |2848       |\n",
      "|ft myers / SW florida  |2840       |\n",
      "|denver                 |2821       |\n",
      "|st louis, MO           |2812       |\n",
      "|spokane / coeur d'alene|2807       |\n",
      "|north jersey           |2802       |\n",
      "|south jersey           |2799       |\n",
      "|cleveland              |2798       |\n",
      "|tucson                 |2791       |\n",
      "+-----------------------+-----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT region,COUNT(1) as COUNTREGION FROM used_cars  \\\n",
    "GROUP BY region ORDER BY COUNTREGION DESC\"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59572ffb",
   "metadata": {},
   "source": [
    "#  Cars by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d60b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|model         |count(1)|\n",
      "+--------------+--------+\n",
      "|f-150         |7116    |\n",
      "|null          |4701    |\n",
      "|silverado 1500|4546    |\n",
      "|1500          |3803    |\n",
      "|camry         |2827    |\n",
      "|silverado     |2780    |\n",
      "|accord        |2749    |\n",
      "|wrangler      |2674    |\n",
      "|civic         |2597    |\n",
      "|escape        |2517    |\n",
      "|altima        |2491    |\n",
      "|2500          |2467    |\n",
      "|tacoma        |2378    |\n",
      "|explorer      |2252    |\n",
      "|grand cherokee|2229    |\n",
      "|mustang       |2019    |\n",
      "|corolla       |1973    |\n",
      "|equinox       |1769    |\n",
      "|cr-v          |1722    |\n",
      "|fusion        |1670    |\n",
      "|focus         |1669    |\n",
      "|corvette      |1617    |\n",
      "|malibu        |1577    |\n",
      "|tahoe         |1524    |\n",
      "|rav4          |1520    |\n",
      "+--------------+--------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 22:==================================================>     (10 + 1) / 11]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model,COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "GROUP BY model \\\n",
    "ORDER BY COUNT(1) DESC\"\n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8997620",
   "metadata": {},
   "source": [
    "#  Calculate Average Price , Standard Deviation for Each Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ebc145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+--------------------+---+----------+\n",
      "|condition|count(1)|Average           |StandardDev         |MIN|MAX       |\n",
      "+---------+--------+------------------+--------------------+---+----------+\n",
      "|null     |151389  |112177.00333577736|1.4667367591470314E7|1  |3024942282|\n",
      "|good     |119155  |33173.68291720868 |3259849.8200198743  |1  |1111111111|\n",
      "|excellent|94925   |54885.52424545694 |1.2128943588720001E7|1  |3736928711|\n",
      "|like new |20060   |38430.82976071785 |1558111.0473921574  |1  |135008900 |\n",
      "|fair     |6729    |765614.2440184277 |4.7999096711095154E7|1  |3736928711|\n",
      "|new      |1132    |27272.732332155476|27116.586017930298  |1  |182000    |\n",
      "|salvage  |595     |3641.8924369747897|4715.988233164577   |1  |35989     |\n",
      "+---------+--------+------------------+--------------------+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT condition,COUNT(1),AVG(price) as Average, \\\n",
    "STDDEV(price) as StandardDev, \\\n",
    "MIN(price) as MIN, \\\n",
    "MAX(price) as MAX \\\n",
    "FROM used_cars \\\n",
    "GROUP BY condition \\\n",
    "ORDER BY COUNT(1) DESC\"\n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42d405",
   "metadata": {},
   "source": [
    "# Count per Group : Model , Manufacturer and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f621e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------+----+--------+\n",
      "|model                     |manufacturer|year|count(1)|\n",
      "+--------------------------+------------+----+--------+\n",
      "|f-150                     |ford        |2018|757     |\n",
      "|f-150                     |ford        |2013|754     |\n",
      "|Scion iM Hatchback 4D     |null        |2016|640     |\n",
      "|f-150                     |ford        |2014|621     |\n",
      "|f-150                     |ford        |2017|571     |\n",
      "|f-150                     |ford        |2016|548     |\n",
      "|f-150                     |ford        |2015|542     |\n",
      "|silverado 1500            |chevrolet   |2015|524     |\n",
      "|silverado 1500            |chevrolet   |2014|509     |\n",
      "|1500                      |ram         |2017|464     |\n",
      "|f-150                     |ford        |2010|434     |\n",
      "|1500                      |ram         |2014|410     |\n",
      "|altima                    |nissan      |2013|405     |\n",
      "|1500                      |ram         |2016|400     |\n",
      "|1500 classic regular cab  |ram         |2019|383     |\n",
      "|silverado 1500            |chevrolet   |2017|371     |\n",
      "|ranger supercab xl pickup |ford        |2020|353     |\n",
      "|f-150                     |ford        |2012|352     |\n",
      "|silverado 1500            |chevrolet   |2018|338     |\n",
      "|f-150                     |ford        |2011|329     |\n",
      "|f-150                     |ford        |2019|329     |\n",
      "|1500                      |ram         |2015|320     |\n",
      "|escape                    |ford        |2018|317     |\n",
      "|expedition xlt sport      |ford        |2017|307     |\n",
      "|wrangler unlimited all new|jeep        |2018|303     |\n",
      "+--------------------------+------------+----+--------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model,manufacturer,year,COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "GROUP BY model,manufacturer,year \\\n",
    "ORDER BY COUNT(1) DESC\"\n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748a602",
   "metadata": {},
   "source": [
    "# Count per Group : Model , Manufacturer and Year with ROLLUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c189c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----+--------+\n",
      "|model|manufacturer|year|count(1)|\n",
      "+-----+------------+----+--------+\n",
      "|null |null        |null|2827    |\n",
      "|camry|null        |null|2827    |\n",
      "|camry|toyota      |null|2825    |\n",
      "|camry|toyota      |2007|253     |\n",
      "|camry|toyota      |2009|199     |\n",
      "|camry|toyota      |2018|194     |\n",
      "|camry|toyota      |2011|188     |\n",
      "|camry|toyota      |2012|186     |\n",
      "|camry|toyota      |2019|143     |\n",
      "|camry|toyota      |2014|137     |\n",
      "|camry|toyota      |2017|134     |\n",
      "|camry|toyota      |2015|132     |\n",
      "|camry|toyota      |2008|126     |\n",
      "|camry|toyota      |2016|118     |\n",
      "|camry|toyota      |2005|117     |\n",
      "|camry|toyota      |2013|115     |\n",
      "|camry|toyota      |2010|110     |\n",
      "|camry|toyota      |2004|103     |\n",
      "|camry|toyota      |2003|87      |\n",
      "|camry|toyota      |2002|83      |\n",
      "|camry|toyota      |2006|72      |\n",
      "|camry|toyota      |2000|71      |\n",
      "|camry|toyota      |2001|54      |\n",
      "|camry|toyota      |1999|50      |\n",
      "|camry|toyota      |2020|41      |\n",
      "|camry|toyota      |1998|35      |\n",
      "|camry|toyota      |1997|27      |\n",
      "|camry|toyota      |1996|20      |\n",
      "|camry|toyota      |1995|9       |\n",
      "|camry|toyota      |1994|5       |\n",
      "|camry|toyota      |1993|5       |\n",
      "|camry|toyota      |2021|3       |\n",
      "|camry|toyota      |1987|2       |\n",
      "|camry|toyota      |1991|2       |\n",
      "|camry|nissan      |null|2       |\n",
      "|camry|toyota      |1992|2       |\n",
      "|camry|nissan      |2017|2       |\n",
      "|camry|toyota      |1989|1       |\n",
      "|camry|toyota      |1990|1       |\n",
      "+-----+------------+----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Equivalent GROUP BY GROUPING SETS \n",
    "# ((model,manufacturer,year), (model,manufacturer),(model), ())\n",
    "sql_query = \"SELECT model,manufacturer,year,COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "WHERE model = 'camry' \\\n",
    "GROUP BY model,manufacturer,year \\\n",
    "WITH ROLLUP ORDER BY COUNT(1) DESC\"\n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7adec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|model|count(1)|\n",
      "+-----+--------+\n",
      "|camry|2827    |\n",
      "+-----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model, COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "WHERE model = 'camry' \\\n",
    "GROUP BY model\" \n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(28,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93905b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------+\n",
      "|model|manufacturer|count(1)|\n",
      "+-----+------------+--------+\n",
      "|camry|toyota      |2825    |\n",
      "|camry|nissan      |2       |\n",
      "+-----+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model, manufacturer ,COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "WHERE model = 'camry' \\\n",
    "GROUP BY model , manufacturer\" \n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(28,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91d78f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----+--------+\n",
      "|model|manufacturer|year|count(1)|\n",
      "+-----+------------+----+--------+\n",
      "|camry|toyota      |2018|194     |\n",
      "|camry|toyota      |2019|143     |\n",
      "|camry|toyota      |1999|50      |\n",
      "|camry|toyota      |2005|117     |\n",
      "|camry|toyota      |2016|118     |\n",
      "|camry|toyota      |2006|72      |\n",
      "|camry|toyota      |2020|41      |\n",
      "|camry|toyota      |2010|110     |\n",
      "|camry|toyota      |2001|54      |\n",
      "|camry|toyota      |2015|132     |\n",
      "|camry|toyota      |1996|20      |\n",
      "|camry|toyota      |1997|27      |\n",
      "|camry|toyota      |2009|199     |\n",
      "|camry|toyota      |2004|103     |\n",
      "|camry|toyota      |2011|188     |\n",
      "|camry|toyota      |2012|186     |\n",
      "|camry|toyota      |1998|35      |\n",
      "|camry|toyota      |2003|87      |\n",
      "|camry|toyota      |2007|253     |\n",
      "|camry|toyota      |2013|115     |\n",
      "|camry|toyota      |2014|137     |\n",
      "|camry|toyota      |2017|134     |\n",
      "|camry|toyota      |2008|126     |\n",
      "|camry|toyota      |2002|83      |\n",
      "|camry|toyota      |1993|5       |\n",
      "|camry|toyota      |2000|71      |\n",
      "|camry|toyota      |1995|9       |\n",
      "|camry|toyota      |1994|5       |\n",
      "|camry|toyota      |1987|2       |\n",
      "|camry|toyota      |1991|2       |\n",
      "|camry|toyota      |1989|1       |\n",
      "|camry|toyota      |1992|2       |\n",
      "|camry|toyota      |2021|3       |\n",
      "|camry|nissan      |2017|2       |\n",
      "|camry|toyota      |1990|1       |\n",
      "+-----+------------+----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model, manufacturer ,year ,COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "WHERE model = 'camry' \\\n",
    "GROUP BY model , manufacturer , year\" \n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ada064",
   "metadata": {},
   "source": [
    "# Count per Group : Model , Manufacturer and Year WITH CUBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "011a7cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----+--------+\n",
      "|model|manufacturer|year|count(1)|\n",
      "+-----+------------+----+--------+\n",
      "|null |null        |null|393985  |\n",
      "|null |ford        |null|64855   |\n",
      "|null |chevrolet   |null|50643   |\n",
      "|null |null        |2018|32644   |\n",
      "|null |null        |2017|32544   |\n",
      "|null |toyota      |null|31600   |\n",
      "|null |null        |2013|28198   |\n",
      "|null |null        |2015|27983   |\n",
      "|null |null        |2016|27401   |\n",
      "|null |null        |2014|26991   |\n",
      "|null |null        |2019|22889   |\n",
      "|null |null        |2012|22334   |\n",
      "|null |honda       |null|19867   |\n",
      "|null |null        |2011|19020   |\n",
      "|null |null        |2020|17807   |\n",
      "|null |jeep        |null|17461   |\n",
      "|null |nissan      |null|17395   |\n",
      "|null |ram         |null|16464   |\n",
      "|null |null        |2008|16281   |\n",
      "|null |null        |null|16185   |\n",
      "|null |gmc         |null|15431   |\n",
      "|null |null        |2010|14985   |\n",
      "|null |null        |2007|14181   |\n",
      "|null |bmw         |null|13745   |\n",
      "|null |dodge       |null|12369   |\n",
      "+-----+------------+----+--------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Equivalent GROUP BY GROUPING SETS \n",
    "# (model,manufacturer,year)\n",
    "# (model,manufacturer)\n",
    "# (manufacturer,year)\n",
    "# (model,year)\n",
    "# (model)\n",
    "# (manufacturer)\n",
    "# (year)\n",
    "# ()\n",
    "\n",
    "\n",
    "sql_query = \"SELECT model,manufacturer,year,COUNT(1) \\\n",
    "FROM used_cars \\\n",
    "GROUP BY model,manufacturer,year \\\n",
    "WITH CUBE ORDER BY COUNT(1) DESC\"\n",
    "\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dac02f",
   "metadata": {},
   "source": [
    "# DISTINCT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3048e5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT model)|\n",
      "+---------------------+\n",
      "|28281                |\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT COUNT(DISTINCT(model)) FROM used_cars \"\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443372bb",
   "metadata": {},
   "source": [
    "# APPROX_COUNT_DISTINCT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84e52c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|approx_count_distinct(model)|\n",
      "+----------------------------+\n",
      "|28426                       |\n",
      "+----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT APPROX_COUNT_DISTINCT(model) FROM used_cars \"\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c8c7fe",
   "metadata": {},
   "source": [
    "# DENSE RANK by Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "813a3ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/26 15:12:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/26 15:12:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 55:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+----+----------+----------+\n",
      "|model                 |manufacturer |year|price     |price_rank|\n",
      "+----------------------+-------------+----+----------+----------+\n",
      "|tundra                |toyota       |2007|3736928711|1         |\n",
      "|4runner               |toyota       |1999|3736928711|1         |\n",
      "|benz e320             |mercedes-benz|2000|3024942282|2         |\n",
      "|benz s430             |mercedes-benz|2000|3024942282|2         |\n",
      "|null                  |chevrolet    |2021|3009548743|3         |\n",
      "|wrangler              |jeep         |1989|1410065407|4         |\n",
      "|vnl                   |volvo        |2006|1234567890|5         |\n",
      "|f350 super duty lariat|ford         |1999|1111111111|6         |\n",
      "|null                  |jeep         |2020|1111111111|6         |\n",
      "|null                  |chevrolet    |1960|987654321 |7         |\n",
      "|null                  |chevrolet    |1960|987654321 |7         |\n",
      "|titan se kingcab      |nissan       |2008|135008900 |8         |\n",
      "|project               |chevrolet    |1965|123456789 |9         |\n",
      "|Chevy/gmc             |null         |2003|123456789 |9         |\n",
      "|sierra 2500           |gmc          |1996|123456789 |9         |\n",
      "|regal                 |buick        |1999|123456789 |9         |\n",
      "|cruze                 |chevrolet    |2015|123456789 |9         |\n",
      "|Rare Car              |null         |2021|123456789 |9         |\n",
      "|null                  |bmw          |1980|113456789 |10        |\n",
      "|ranger                |ford         |1993|99999999  |11        |\n",
      "|camaro                |chevrolet    |1991|25003000  |12        |\n",
      "|2500                  |ram          |2007|17000000  |13        |\n",
      "|null                  |chevrolet    |2019|12345678  |14        |\n",
      "|null                  |chevrolet    |2019|12345678  |14        |\n",
      "|null                  |chevrolet    |2019|12345678  |14        |\n",
      "+----------------------+-------------+----+----------+----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model,manufacturer,year, \\\n",
    "price, \\\n",
    "DENSE_RANK () OVER ( \\\n",
    "ORDER BY price DESC \\\n",
    ") price_rank \\\n",
    "FROM used_cars \"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75a443",
   "metadata": {},
   "source": [
    "# DENSE RANK Order by Price Partition by manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bc98972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------+----+---------+----------+\n",
      "|model                      |manufacturer|year|price    |price_rank|\n",
      "+---------------------------+------------+----+---------+----------+\n",
      "|Chevy/gmc                  |null        |2003|123456789|1         |\n",
      "|Rare Car                   |null        |2021|123456789|1         |\n",
      "|all                        |null        |2021|5000000  |2         |\n",
      "|any and all                |null        |2002|3226714  |3         |\n",
      "|Recycling                  |null        |1902|1666666  |4         |\n",
      "|Any make any model         |null        |2022|1000000  |5         |\n",
      "|Call for a free estimate   |null        |2019|1000000  |5         |\n",
      "|Any make any model         |null        |2022|1000000  |5         |\n",
      "|Any make any model         |null        |2022|1000000  |5         |\n",
      "|f250 xlt crewcab           |null        |2019|554900   |6         |\n",
      "|Lambo Aventador SV Roadster|null        |2016|516999   |7         |\n",
      "|hINO 268                   |null        |2016|470000   |8         |\n",
      "|any and all                |null        |2003|400123   |9         |\n",
      "|Lamborghini Huracan        |null        |2017|299991   |10        |\n",
      "|Lamborghini Huracan        |null        |2017|299991   |10        |\n",
      "|Lamborghini Huracan        |null        |2017|299991   |10        |\n",
      "|Lamborghini Huracan        |null        |2017|299991   |10        |\n",
      "|Lamborghini Aventador      |null        |2018|299500   |11        |\n",
      "|Lamborghini Aventador      |null        |2018|299500   |11        |\n",
      "|Lamborghini Aventador      |null        |2018|299500   |11        |\n",
      "|Lamborghini Aventador      |null        |2018|299500   |11        |\n",
      "|Lamborghini huracan evo    |null        |2021|285000   |12        |\n",
      "|rolls royce dawn           |null        |2018|279888   |13        |\n",
      "|ROLLS ROYCE GHOST          |null        |2018|269950   |14        |\n",
      "|Rolls royce dawn           |null        |2017|261895   |15        |\n",
      "+---------------------------+------------+----+---------+----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT model,manufacturer,year,price, \\\n",
    "DENSE_RANK () OVER ( \\\n",
    "PARTITION BY manufacturer \\\n",
    "ORDER BY price DESC \\\n",
    ") price_rank \\\n",
    "FROM used_cars \"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88dab774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+----+---------+----------+\n",
      "|model              |manufacturer|year|price    |price_rank|\n",
      "+-------------------+------------+----+---------+----------+\n",
      "|Chevy/gmc          |null        |2003|123456789|1         |\n",
      "|Rare Car           |null        |2021|123456789|1         |\n",
      "|all                |null        |2021|5000000  |2         |\n",
      "|any and all        |null        |2002|3226714  |3         |\n",
      "|regal              |buick       |1999|123456789|1         |\n",
      "|lacrosse           |buick       |2013|123456   |2         |\n",
      "|skylark convertible|buick       |1953|110000   |3         |\n",
      "|xk 150             |jaguar      |1959|150000   |1         |\n",
      "|xk 150 se dhc      |jaguar      |1959|150000   |1         |\n",
      "|xk150 se dhc       |jaguar      |1959|150000   |1         |\n",
      "|xk150 se dhc       |jaguar      |1959|150000   |1         |\n",
      "|xke                |jaguar      |1971|75000    |2         |\n",
      "|null               |jaguar      |1970|65000    |3         |\n",
      "|ipace              |jaguar      |2020|65000    |3         |\n",
      "|defender 110       |land rover  |1986|55000    |1         |\n",
      "|rangerover sport   |land rover  |2016|47995    |2         |\n",
      "|hse                |land rover  |2010|10999    |3         |\n",
      "|lc                 |lexus       |2021|114950   |1         |\n",
      "|lc                 |lexus       |2021|110000   |2         |\n",
      "|lx                 |lexus       |2020|98000    |3         |\n",
      "|null               |mitsubishi  |2014|40000    |1         |\n",
      "|lancer evolution   |mitsubishi  |2008|39999    |2         |\n",
      "|lancer evolution   |mitsubishi  |2015|39999    |2         |\n",
      "|lancer evolution   |mitsubishi  |2015|39999    |2         |\n",
      "|fuso crew cab      |mitsubishi  |2014|39900    |3         |\n",
      "+-------------------+------------+----+---------+----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"SELECT * FROM ( SELECT model,manufacturer,year,price, \\\n",
    "DENSE_RANK () OVER ( \\\n",
    "PARTITION BY manufacturer \\\n",
    "ORDER BY price DESC \\\n",
    ") price_rank \\\n",
    "FROM used_cars ) t \\\n",
    "WHERE price_rank < 4 \"\n",
    "\n",
    "sqlDF = spark.sql(sql_query)\n",
    "sqlDF.show(25,truncate = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
